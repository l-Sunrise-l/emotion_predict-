{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/skillbox-computer-vision-project/sample_submission.csv')\ntest.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel = load_model(\"/kaggle/input/model-new-v4/model.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_dict = {0:'anger',1:'contempt',2:'disgust',3:'fear',4:'happy',5:'neutral',6:'sad',7:'surprise',8:'uncertain'}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n\ndef preprocess_input(x, data_format=None, version=1):\n    x_temp = np.copy(x)\n    if data_format is None:\n        data_format = K.image_data_format()\n    assert data_format in {'channels_last', 'channels_first'}\n\n    if version == 1:\n        if data_format == 'channels_first':\n            x_temp = x_temp[:, ::-1, ...]\n            x_temp[:, 0, :, :] -= 93.5940\n            x_temp[:, 1, :, :] -= 104.7624\n            x_temp[:, 2, :, :] -= 129.1863\n        else:\n            x_temp = x_temp[..., ::-1]\n            x_temp[..., 0] -= 93.5940\n            x_temp[..., 1] -= 104.7624\n            x_temp[..., 2] -= 129.1863\n\n    elif version == 2:\n        if data_format == 'channels_first':\n            x_temp = x_temp[:, ::-1, ...]\n            x_temp[:, 0, :, :] -= 91.4953\n            x_temp[:, 1, :, :] -= 103.8827\n            x_temp[:, 2, :, :] -= 131.0912\n        else:\n            x_temp = x_temp[..., ::-1]\n            x_temp[..., 0] -= 91.4953\n            x_temp[..., 1] -= 103.8827\n            x_temp[..., 2] -= 131.0912\n    else:\n        raise NotImplementedError\n\n    return x_temp","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_input_facenet(image_):\n\n    preprocessed = preprocess_input(image_, version=2)\n    \n    return preprocessed\n\nimage_gen = ImageDataGenerator(preprocessing_function=preprocess_input_facenet) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 128\nIMAGE_SIZE = 224\n\ndata = image_gen.flow_from_dataframe(\n    test,\n    directory='/kaggle/input/test-data/test_kaggle',\n    x_col='image_path',\n    y_col='emotion',\n    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = model.predict(data)\nemotion_cm = [predict_dict[np.argmax(i)] for i in emotion]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['emotion'] = emotion_cm\ntest.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_csv('/kaggle/working/submission.csv', sep=',', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"С этого момента было 17 ноутбуков и они +- одинаковые. Отличались только предобученные модели. Я исправил тестовый датасет, теперь shuffle = True и он образуеться от датафрейма. Также я изменил спооб искусственного увеличения датасета для обучения. Я увеличил изначальный датасет в 14 раз с помощью библеотеки \"albumentations\":\n\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nimport albumentations as A\n\nfrom PIL import Image\n\nfrom os import listdir\n\nimport tensorflow as tf\n\nimport numpy as np\n\ntransform_1 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.HorizontalFlip(p=1),\n            A.RandomBrightnessContrast(p=1),\n        ])\n\ntransform_2 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.Blur(blur_limit=6, always_apply=True),\n        ])\n\ntransform_3 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.ChannelDropout (channel_drop_range=(1, 1), fill_value=0, p=1),\n        ])\n\ntransform_4 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.CLAHE (clip_limit=4.0, tile_grid_size=(8, 8), p=1),\n        ])\n\ntransform_5 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.ColorJitter (brightness=1, contrast=1, saturation=1, hue=1, p=1),\n        ])\n\ntransform_6 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.Downscale (scale_min=0.25, scale_max=0.25, interpolation=None, p=1),\n        ])\n\ntransform_7 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.Emboss (alpha=(0.2, 0.5), strength=(0.2, 0.7), p=1),\n        ])\n\ntransform_8 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.Equalize (mode='cv', by_channels=True, mask=None, mask_params=(), p=1),\n        ])\n\ntransform_9 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.FancyPCA (alpha=1, p=1),\n        ])\n\ntransform_10 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.GaussNoise (var_limit=(100.0, 500.0), mean=0, per_channel=True,p=1),\n        ])\n\ntransform_11 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.GlassBlur (sigma=0.7, max_delta=4, iterations=2, mode='fast', p=1),\n        ])\n\ntransform_12 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.HueSaturationValue (hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=1),\n        ])\n\ntransform_13 = A.Compose([\n            A.RandomCrop(width=224, height=224),\n            A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), always_apply=False, p=1),\n        ])\n\ndef new_image(transform,image,i):\n\n    transformed = transform(image=image)[\"image\"]\n    \n    img = Image.fromarray(transformed, 'RGB')\n    \n    img.save(\"D://Загрузки//train//train//\" + i1 + '//+'+ str(i)+ '_' + i2)\n\ndef new_image_1(transform,image,i):\n\n    transformed = transform(image=image)[\"image\"]\n    \n    img = Image.fromarray(transformed, 'RGB')\n    \n    img.save(\"D://Загрузки//train//train_1//\" + i1 + '//+'+ str(i)+ '_' + i2)\n\nfor i1 in listdir('D://Загрузки//train//train'):\n\n    for i2 in listdir('D://Загрузки//train//train//'+i1):\n\n        img = tf.keras.preprocessing.image.load_img('D://Загрузки//train//train//'+i1+'//'+i2,\n                                                      target_size=(256, 256))\n        image = np.array(img)\n        for i,transform in enumerate([transform_1,transform_2,transform_3,transform_4,transform_5,transform_6,transform_7,transform_8,transform_9,transform_10,transform_11,transform_12,transform_13]):\n            new_image(transform,image,i)\n\nfor i1 in listdir('D://Загрузки//train//train_1'):\n\n    for i2 in listdir('D://Загрузки//train//train_1//'+i1):\n        img = tf.keras.preprocessing.image.load_img('D://Загрузки//train//train_1//'+i1+'//'+i2,\n                                                      target_size=(256, 256))\n        image = np.array(img)\n        for i,transform in enumerate([transform_1,transform_2,transform_3,transform_4,transform_5,transform_6,transform_7,transform_8,transform_9,transform_10,transform_11,transform_12,transform_13]):\n            new_image_1(transform,image,i)\n            \n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nПри обучении я использовал разные модели:\n\n№1\n\nbase_model = tf.keras.Model([vggface_model.input], vggface_model.get_layer(\"activation_49\").output)\n\nmodel = tf.keras.Sequential([\n  base_model,\n  \n  Dropout(0.5),\n  \n  Conv2D(2048, (3, 3),activation='relu',padding='same'),\n  \n  Conv2D(2048, (3, 3),activation='relu',padding='same'),\n  \n  BatchNormalization(),\n  \n  MaxPooling2D(pool_size=(7, 7)),\n  \n  Dropout(0.5),\n  \n  Flatten(), # Конвертация в двумерный тензор\n  \n  Dense(256, activation='relu'),\n  \n  Dense(128, activation='relu'),\n  \n  BatchNormalization(),\n  \n  Dropout(0.2),\n  \n  Dense(9, activation='softmax')\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n              loss=\"categorical_crossentropy\",\n              metrics=['accuracy'])\n              \n№2\n\nbase_model = tf.keras.Model([vggface_model.input], vggface_model.get_layer(\"conv5_3_3x3/bn\").output)\n\nmodel = tf.keras.Sequential([\n  base_model,\n  \n  Conv2D(1024, (3, 3),activation='relu',padding='same'),\n  \n  Conv2D(1024, (3, 3),activation='relu',padding='same'),\n  \n  BatchNormalization(),\n  \n  MaxPooling2D(pool_size=(2, 2)),\n  \n  Dropout(0.5),\n  \n  Conv2D(2048, (3, 3),activation='relu',padding='same'),\n  \n  Conv2D(2048, (3, 3),activation='relu',padding='same'),\n  \n  BatchNormalization(),\n  \n  Dropout(0.5),\n  \n  Flatten(),\n  \n  Dense(256, activation='relu'),\n  \n  Dense(128, activation='relu'),\n  \n  BatchNormalization(),\n  \n  Dropout(0.2),\n  \n  Dense(9, activation='softmax')\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n              loss=\"categorical_crossentropy\",\n              metrics=['accuracy'])\n              \n№3\n\nbase_model = tf.keras.Model([vggface_model.input], vggface_model.get_layer(\"flatten_1\").output)\n\nmodel = tf.keras.Sequential([\n  base_model,\n  \n  tf.keras.layers.Dense(1024, activation='relu'),\n  \n  tf.keras.layers.Dense(512, activation='relu'),\n  \n  tf.keras.layers.Dense(256, activation='relu'),\n  \n  tf.keras.layers.Dense(128, activation='relu'),\n  \n  tf.keras.layers.Dense(64, activation='relu'),\n  \n  tf.keras.layers.Dense(32, activation='relu'),\n  \n  tf.keras.layers.Dense(16, activation='relu'),\n  \n  tf.keras.layers.Dense(9, activation='softmax')\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n              loss=\"categorical_crossentropy\",\n              metrics=['accuracy'])\n              \n№4\n\nmodel = Sequential([\n    Conv2D(64, (5, 5), input_shape=(48,48,3), activation='relu', padding='same'),\n    \n    Conv2D(64, (5, 5), activation='relu', padding='same'),\n    \n    BatchNormalization(),\n    \n    MaxPooling2D(pool_size=(2, 2)),\n    \n    Dropout(0.5),\n\n    Conv2D(128, (5, 5),activation='relu',padding='same'),\n    \n    Conv2D(128, (5, 5),activation='relu',padding='same'),\n    \n    BatchNormalization(),\n    \n    MaxPooling2D(pool_size=(2, 2)),\n    \n    Dropout(0.5),\n\n    Conv2D(256, (3, 3),activation='relu',padding='same'),\n    \n    Conv2D(256, (3, 3),activation='relu',padding='same'),\n    \n    BatchNormalization(),\n    \n    MaxPooling2D(pool_size=(2, 2)),\n    \n    Dropout(0.5),\n\n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    \n    BatchNormalization(),\n    \n    Dropout(0.2),\n    \n    Dense(9, activation='softmax')\n])\n\nmy_optimiser = tf.keras.optimizers.Adam(\n                    learning_rate=0.001, \n                    beta_1=0.9, \n                    beta_2=0.999, \n                    epsilon=1e-07, \n                    amsgrad=False,\n                    name='Adam')\n\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=my_optimiser)\n\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nЛучшей моделью оказалась №3. При обучении моделей с 1-3, они начинали переобучаться на 2 эпохе.\n\nТаким образом лучшего результата получилось достичь при увеличении датасета в 14 раз с помощью библиотеки \"albumentations\". Также при разбиении данных на тестовые и валидационные 9к1.\nИ использовании модели под №3. В итоге Score на тестовых данных: 0.5252.","metadata":{}}]}